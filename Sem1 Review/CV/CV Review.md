[TOC]

çŸ©é˜µè®¡ç®—å™¨ï¼šhttps://matrix.reshish.com/multiplication.php

ç§‘å­¦è®¡ç®—å™¨ï¼šhttps://www.desmos.com/scientific?lang=zh-CN

# Week1 Introduction

## 1.1 Ill-posed and Well-posed

- Well-posed: Mapping from world to image (3D to 2D) is **unique** -> forward problem
- Ill-posed: Mapping from image to world (2D to 3D) is **NOT unique** -> inverse problem
- To recover depth, we need extra information
  - another image or
  - pior knowledge about the structure of the scene



# Week2 Image Formation

## 2.1 Physics of image formation

### 2.1.1 Ingredients of image formation

- Radiometric parameters (intensity/colour) --> å†³å®šå›¾ç‰‡äº®åº¦ä¸é¢œè‰²
  - Illumination
  - Surface reflectance properties
  - Sensor properties
- Geometric parameters -->å†³å®šä½ç½®
  - Camera position
  - Camera optics
  - projection geometry

### 2.1.2 Pinhole camera

- Focusç„¦ç‚¹ï¼šall rays coming from a scene point converge into a single image point
- Exposureæ›å…‰æ—¶é—´ï¼šis the time needed to allow enough light through to form an image
  - The longer the exposure the more blurred an image is likely to be
- Apertureèƒ¶åœˆ: the smaller the aperture, the longer the exposure time
- å°pinholeä¼šå¯¼è‡´å¯¹ç„¦æ¸…æ™°ï¼Œä½†å›¾åƒæ¨¡ç³Š; å¤§pinholeï¼Œæ›´äº®çš„å›¾åƒä½†æ¨¡ç³Šï¼›
  - éœ€è¦Lensæ‰èƒ½äº§ç”Ÿæ¸…æ™°ï¼Œåœ¨ç„¦ç‚¹ï¼Œæ˜äº®çš„ç…§ç‰‡
- pinhole cameraæ‰€æœ‰çš„ä¸œè¥¿éƒ½åœ¨ç„¦ç‚¹ä¸Šï¼Œæ— è®ºimage plan lengthæ˜¯å¤šå°‘
  - pinhole camera has an infinite focal range, image will be in focus no matter waht distance the image plan is from the plane

### 2.1.3 Lens

$\frac{1}{f} = \frac{1}{z} + \frac{1}{z'}$

f = focal length

z = distance of object from the lens

z' = distance of image from the lens

## 2.2 Geometry of Image Formation

### 2.2.1 Intrinsic Parameters

Maps points on the **image plan** into **pixel image coordinates**

P' = M P æŠŠç›¸æœºä¸­çš„æŸç‚¹Pé€šè¿‡æŠ•å½±çŸ©é˜µMå˜æ¢åˆ°äº†åƒç´ åæ ‡ä¸­

### 2.2.2 Extrinsic Parameters



### 2.2.3 Digital image

TOP Left is Origin

- Pixelisationï¼šæ¯ä¸ªå°åŒºåŸŸå–å¹³å‡å€¼ï¼ˆMincraftä¸­çš„åƒç´ é£ï¼‰
- Quantizationï¼šç”¨ä¸€ä¸ªfinite num of discrete valueä»£æ›¿intensity value
  - æ¯”å¦‚1bit/pixel = $2^1$Gray levels ï¼ˆ**BINARY IMAGE**ï¼‰ï¼Œè¡¨ç¤º1bitå¯ä»¥è¡¨ç¤ºä¸¤ç§ä¸åŒçš„pixel, å³ä¸º0å’Œ1
  - 2bits/pixel = $2^2$Gray levelsï¼Œè¡¨ç¤º2bitså¯ä»¥è¡¨ç¤º4ç§ä¸åŒçš„pixelï¼Œä¸€å¼ å›¾ç”¨4ç§ä¸ä¸€æ ·çš„pixelæ¥è¡¨ç¤º, ä¸€å¼ å›¾ä¸­å¯ä»¥æ˜ å°„åˆ°[0,63], [64, 127], [128,191], [192, 255]è¿™å››ä¸ªåŒºé—´å†…ã€‚
  - 8bits/pixel = $2^8$Gray levelsï¼Œè¡¨ç¤º8bitså¯ä»¥è¡¨ç¤º256ç§ä¸åŒçš„pixelï¼Œä¸€å¼ å›¾ç”¨256ç§ä¸ä¸€æ ·çš„pixelæ¥è¡¨ç¤ºï¼Œå³ä¸º**åŸå›¾**

## 2.3 Camera Sensors

### 2.3.1 Demosaicing

Demosaicing is a process that computes the colour(RGB values) at every pixel based on the local red, green and blue values.

Demosaicing is a method of interpolation

#### 2.3.1.1 Nearest Neighbour Interpolation

æ‹·è´æœ€è¿‘é‚»ç›¸åŒè‰²çš„pixel value

#### 2.3.1.2 Bilinear Interpolation

å–æœ€è¿‘é‚»ç›¸åŒè‰²ä¸¤ä¸ªæˆ–å››ä¸ªpixelçš„å¹³å‡å€¼

#### 2.3.1.3 Smooth Hue Transition Interpolation

- å¯¹äºç»¿è‰²pixelï¼šä¸Bilinear Interpolationç›¸åŒ
- å¯¹äºçº¢å’Œè“è‰²pixelï¼šBilinear Interpolation of the ratio between red/blue and green

#### 2.3.1.4 Edge-Directed Interpolation

- calculate horizontal H and vertical gradients V
- If H < V, Gx = averay of æ°´å¹³é‚»è¿‘çš„G
- If H > V, Gx = averay of å‚ç›´é‚»è¿‘çš„G
- elseï¼ŒGx = averay ofé‚»è¿‘çš„G



## 2.4 Eye

### 2.4.1 Photoreceptor

å…‰æ„Ÿå—å™¨å¯ä»¥æŠŠå…‰ä¿¡å·è½¬æ¢ä¸ºç”µä¿¡å·

1. PhotoreceptoråŒ…æ‹¬ï¼š

- Rodsæ†ä½“ç»†èƒï¼šhigh sensitivityï¼ˆå¯åœ¨å…‰çº¿æ˜æš—çš„æƒ…å†µä¸‹å·¥ä½œï¼‰
- Conesåœ†é”¥ç»†èƒï¼šlow sensitvityï¼ˆéœ€è¦æ˜äº®çš„å…‰çº¿ï¼‰ï¼Œæœ‰ä¸‰ç§ä¸åŒç§ç±»çš„coneså¯¹ä¸åŒæ³¢é•¿æ•æ„Ÿ
  - Blue
  - Green
  - Red

2. Photoreceptorä¸æ˜¯å‡åŒ€åˆ†å¸ƒåœ¨è§†ç½‘è†œä¸Šçš„

- blind spotï¼šæ— Photoreceptor
- foveaï¼šno rods, high density of cones. **#Green cones > # Red cones << #Blue cones** å¯¹ç»¿è‰²æœ€æ•æ„Ÿ
- peripheryï¼šhigh concentration of rodsï¼Œfew cones

### 2.4.2 Ganglion cells

ç¥ç»èŠ‚ç»†èƒï¼šè§†ç½‘è†œæœ€ç»ˆæ®µçš„ç¥ç»ç»†èƒ

ä¸¤ç§ç±»å‹ï¼š

- ON-centre, off-surround: active if central stimulus is **brighter** than background
- Off-centre, ON-surround: active if  central stimulus is **darker** than background

è§†ç½‘è†œä¸Šçš„Photoreceptorå…‰æ„Ÿå—å™¨(æ†ä½“ç»†èƒå’Œé”¥ä½“ç»†èƒ)é€šè¿‡æ¥å—å…‰å¹¶å°†å®ƒè½¬æ¢ä¸ºè¾“å‡ºç¥ç»ä¿¡å·è€Œæ¥å½±å“è®¸å¤šç¥ç»èŠ‚ç»†èƒä»¥åŠè§†è§‰çš®å±‚ä¸­çš„ç¥ç»ç»†èƒï¼åè¿‡æ¥ï¼Œä»»ä½•ä¸€ç§ç¥ç»ç»†èƒçš„è¾“å‡ºéƒ½ä¾èµ–äºè§†ç½‘è†œä¸Šçš„Photoreceptorå…‰æ„Ÿå—å™¨ï¼æˆ‘ä»¬ç§°ç›´æ¥æˆ–é—´æ¥å½±å“æŸä¸€ç‰¹å®šç¥ç»ç»†èƒçš„å…‰æ„Ÿå—å™¨ç»†èƒçš„å…¨ä½“ä¸ºè¯¥ç‰¹å®šç¥ç»ç»†èƒçš„æ„Ÿå—é‡(receptive field), æ¯”å¦‚**ç¥ç»èŠ‚ç»†èƒçš„æ„Ÿå—é‡å°±æ˜¯ç¥ç»èŠ‚ç»†èƒä¸­çš„æ‰€æœ‰Photoreceptor**

åœ¨è§†è§‰ç³»ç»Ÿä¸­ï¼Œä»»ä½•å±‚æ¬¡æˆ–æ°´å¹³ä¸Šçš„å•ä¸ªç¥ç»ç»†èƒå‡åœ¨è§†ç½‘è†œä¸Šæœ‰ä¸€ç‰¹å®šä»£è¡¨åŒºåŸŸï¼Œåœ¨è¯¥åŒºåŸŸä¸Šçš„å…‰å­¦åˆºæ¿€èƒ½å½±å“è¯¥ç¥ç»ç»†èƒçš„æ´»åŠ¨ï¼Œè¿™ä¸ªåŒºåŸŸå®šä¹‰ä¸ºè¯¥ç»†èƒçš„è§†è§‰æ„Ÿå—é‡ã€‚

Colour Opponent Cells

- Red ON/Green OFF, Red OFF/Green ON
- Green ON/Red OFF, Green OFF/Red ON
- Blue ON/Yellow OFF, Blue OFF/Yellow ON
- Yellow ON/Blue OFF, Yellow OFF/Blue ON

Yellow æ˜¯redå’Œgreençš„å¹³å‡å€¼

The standard way of modelling ganglion cell receptive field is by using a DOG operator

# Week3 Low Level (Artificial)

## 3.1 Convolution and Correlation

- If mask is symmetrical, then cross-correlation = convolution
- Convolution: å…ˆé¡ºæ—¶é’ˆæ—‹è½¬180åå†ç›¸ä¹˜
- cross-correlationä¸æ»¡è¶³ç»“åˆå¾‹å’Œäº¤æ¢å¾‹

## 3.2 Smoothing

å¹³æ»‘é«˜é¢‘ç‡

- Gaussian mask
  - standard deviationè¶Šå¤§ï¼Œå·ç§¯å®Œè¶Šæ¨¡ç³Šï¼Œå› ä¸ºæ›´å¤šçš„pixelè¢«å¹³æ»‘
  - mask widthèµ·ç è¦å¤§äºç­‰äº6å€çš„standard deviation
  - 2Dé«˜æ–¯æ ¸å¯ä»¥æ‹†è§£ä¸ºä¸¤ä¸ª1Dé«˜æ–¯æ ¸çš„ä¹˜ç§¯

## 3.3 Differencing mask

The difference between pixel values measures the gradient of the intensity values

<img src="/Users/kevin/Library/Application Support/typora-user-images/image-20220103004945158.png" alt="image-20220103004945158" style="zoom:30%;" />

### 3.3.1 Laplacian mask

```
-1 -1 -1
-1  8 -1          or 
-1 -1 -1

-1/8 -1/8 -1/8            -1  -1  -1
-1/8   1  -1/8     or     -1   8  -1
-1/8 -1/8 -1/8            -1  -1  -1
```

å¯ä»¥æ£€æµ‹æ°´å¹³ï¼Œå‚ç›´ï¼Œå¯¹è§’è¾¹, å’Œä¸º1



**Laplacian mask and Difference masks are  sensitive to noise. **



## 3.4 Edge Detection

### 3.4.1 Intensity discontinuities

- Depth discontinuity
- Orientation discontinuity
- Reflectance discontinuity
- Illumination discontinuity

### 3.4.2 LoG / DoG Mask

è¾¹ç¼˜æ£€æµ‹ï¼šå…ˆé«˜æ–¯å¹³æ»‘å†ä¸Laplacian maskå·ç§¯æ£€æµ‹è¾¹ç¼˜ï¼Œç›¸å½“äºé«˜æ–¯æ ¸*Laplacian mask

LoG = Gaussian mask * Laplacian mask

<img src="/Users/kevin/Library/Application Support/typora-user-images/image-20220103010149896.png" alt="image-20220103010149896" style="zoom:30%;" />

å¯ä»¥ç”¨DoGæ¥è¿‘ä¼¼LoGï¼ŒDoGæ˜¯ç”¨ä¸¤ä¸ªä¸åŒå°ºåº¦çš„é«˜æ–¯æ ¸ç›¸å‡ï¼Œå¾—åˆ°LoG



é™¤LoGä¹‹å¤–ï¼Œè¿˜å¯ä»¥ä½¿ç”¨ä¸€é˜¶é«˜æ–¯åå¯¼æ ¸æ¥æ£€æµ‹æ°´å¹³å’Œå‚ç›´è¾¹ç¼˜ï¼š

<img src="/Users/kevin/Library/Application Support/typora-user-images/image-20220103010705799.png" alt="image-20220103010705799" style="zoom:30%;" />

å³è¾¹çš„ä¸€é˜¶é«˜æ–¯åå¯¼æ ¸ = é«˜æ–¯æ ¸ * ä¸€ç»´å·ç§¯

## 3.5 Canny Edge detector

- Filter image with derivative of Gaussian
- Calculate the gradient magnitude and orientation
- Non-maximum suppression(ç»†åŒ–ç²—è¾¹)
- Linking and thresholding(hysteresis):
  - i.   Define high and low thresholds
  - ii.   Apply a high threshold on the magnitude to initialize a contours and continue tracing the contour until the magnitude falls below a low threshold

## 3.6 Image Pyramids

### 3.6.1 Gaussian Pyramid

a Gaussian image pyramid is a multiscale representation of a single image at different resolutions obtained by iteratively convolving an image with a Gaussian filter and down-sampling.

### 3.6.2 Laplacian Pyramid

a Laplacian image pyramid is a multiscale representation of a single image that highlights intensity discontinuities at multiple scales. It is obtained by iteratively convolving an image with a Gaussian filter, subtracting the smoothed image from the previous one, and down-sampling the smoothed image.

# Week4 Low & Middle Level (Biological)

## 4.1 The Bio Visual System

- LGNï¼ˆå¤–ä¾§è†çŠ¶ä½“æ ¸ï¼‰
- Cerebral Cortexï¼ˆå¤§è„‘çš®å±‚ï¼‰

## 4.2 Primary Visual Cortex

V1 Cell have RF selective forï¼š

- colour
- orientation
- direction of motion
- spatial frenquency
- eye of origin
- binocular disparity
- position

V1 RFs Orientationï¼š

- Simple Cellsï¼šåªå›åº”ç‰¹å®šæ–¹å‘ï¼Œå¸¸è¢«ç”¨ä½œedge and bar detectors
- Complex Cellsï¼šå¯¹ä½ç½®æ›´invarianceï¼Œæ‰€ä»¥å¸¸ç”¨ä½œedge and bar detectors with some tolerance to location
- Hyper Complex Cellsï¼šä¸ä»…èƒ½å›åº”ç‰¹å®šæ–¹å‘ï¼Œè¿˜èƒ½å›åº”ç‰¹å®šé•¿åº¦çš„

## 4.3 Gabor Functions

Energy Model

## 4.4 Non-Classical RFs

- Classical Receptive Fieldï¼ˆcRFï¼‰= the region

## 4.5 Gestalt Laws

Image segmentation in the brain

- é€šè¿‡Top-downçš„æ–¹å¼åˆ†å‰²å›¾åƒ

- é€šè¿‡Bottom-upçš„æ–¹å¼åˆ†å‰²å›¾åƒ(Gestalt laws)

Gestalt laws:

1. Proximity
2. Similarity
3. Closure
4. Continuity
5. Common Fate
6. Symmetry
7. Common Region
8. Connectivity

## 4.6 Border Ownership

æŸè¾¹åˆ°åº•å±äºè°

V2 Border-ownership cells

Border ownership refers to the fact that the boundary between two regions in an image is perceived as part of one region (the foreground) and not the other region (the background). This means that foreground objects have a defined shape (delineated by the border), whereas background objects appear shapeless.

# Week5 Mid-Level Segmentation (Segmentation)

## 5.1 Thresholding

1. Average intensity
2. Intensity Histogram
3. Hysteresis thresholding

### 5.1.1 Morphological Operations

1. Dilation: Fill holes
   1. Full match => 1
   2. Some match => 1
   3. no match =>0
2. Erosion: Remove bridges, branches, noise
   1. Full match => 1
   2. Some match => 0
   3. no match =>0

## 5.2 Region-based

å…·ä½“è¯·çœ‹tutorial5 answer

### 5.2.1 Region Growing

### 5.2.2 Region Merging

### 5.2.3 Region Splitting and Merging

## 5.3 Clustering Methods

### 5.3.1 K-means

- Randomly choose k points to act as cluster centres 
  - For each data point 
    - Calculate its similarity to each cluster centre 
    -  Allocate data point to closest cluster centre 
  - Repeat from step 2 for each data point 
  - For each cluster centre 
  
    - Calculate its new position as the mean position its elements 
  - Repeat from step 6 for each cluster centre 
- Repeat from step 2 until the cluster centres are unchanged

### 5.3.2 Agglomerative clustering

- single-link clustering
  - Distance between clusters is shortest distance between elements (MIN distance)
-  complete-link clustering 
  - distance between clusters is longest distance between elements (MAX distance) 
- group-average clustering
  -  distance between clusters is average distance between all pairs of elements (AVERAGE distance) 
- centroid clustering
  -  distance between clusters is distance between their averages.

### 5.3.3 Group Cutting

$Ncut(A,B) = \frac{cut(A,B)}{assoc(A,V)}+\frac{cut(A,B)}{assis(B,V)}$

åˆ†å­ï¼šAå’ŒBä¸­æ‰€æœ‰è¿æ¥çš„edgeçš„weightsä¹‹å’Œï¼ˆçº¢çº¿ï¼‰

åˆ†æ¯ï¼šAæˆ–Bé›†åˆæ‰€æœ‰çš„edgeä¹‹å’Œ

è¦é¿å…æŠŠAåˆ‡æˆä¸€ä¸ªåƒç´ ï¼ŒBæ˜¯ä¸€ä¸ªæ•´ä½“ï¼›æˆ–è€…Aæ˜¯ä¸€ä¸ªæ•´ä½“ï¼ŒBæ˜¯ä¸€ä¸ªåƒç´ 

å¦‚æœAé›†åˆæœ‰å¾ˆå¤šç‚¹ï¼Œåˆ™åˆ†æ¯ä¼šå˜å¤§ï¼Œæ•´ä½“ä¼šå˜å°ï¼Œæ•´ä½“å˜å°å°±ä¼šè¢«åˆ†å‰²ï¼Œåˆ‡å‰²åå°±ä¿è¯äº†Aå‡ ä½•ä¸­æœ‰å¾ˆå¤šç‚¹è€Œä¸æ˜¯ä¸€ä¸ªåƒç´ 

å½“Aå’ŒBé›†åˆé‡Œéƒ½æœ‰å¾ˆå¤šåƒç´ ç‚¹æ—¶ï¼ŒNCutè¾¾åˆ°æœ€å°ï¼Œä¼šè¢«å®‰å…¨åˆ‡å‰²

## 5.4 Fitting

### 5.4.1 Hough Transform

### 5.4.2 Active Contours

Energy = Internal energy + External energy 

- Internal energy is a function of the shape of the contour, it is reduced if the curve is short and smooth.
- External energy is a function of the image features near the contour, it is reduced if the intensity gradient is high.

# Week6 Mid-Level Correspondence

æ‰¾ä¸¤å¼ å›¾ç‰‡ä¸­çš„å¯¹åº”ç‚¹å­˜åœ¨çš„é—®é¢˜ï¼š

- é®æŒ¡
- False match
- å¤§çš„æœç´¢ç©ºé—´

## 6.1 Correlation-based methods

ä½¿ç”¨æ»‘çª—ï¼Œå¯¹æ¯”æ¯ä¸€ä¸ªåƒç´ çš„ç›¸ä¼¼åº¦æ¥æ‰¾å¯¹åº”ç‚¹

éœ€è¦å¤§é‡è®¡ç®—ï¼Œéš¾ä»¥ç¡®å®šWindowså¤§å°ï¼Œç‰©ä½“é®æŒ¡ï¼Œå‘å…‰ä¸èƒ½å¾ˆå¥½çš„è®¡ç®—å‡ºå¯¹åº”ç‚¹

### 6.2 Feature-based methods

å…ˆæå–ç‰¹å¾ï¼ˆinterest Pointsï¼‰ï¼Œå†å¯¹æ¯”ç‰¹å¾ç›¸ä¼¼åº¦æ¥æ‰¾å¯¹åº”ç‚¹

### 6.2.1 Interest Points

è§’ç‚¹corneræä¾›äº†å¾ˆå¥½çš„ä¿¡æ¯ï¼Œæ¥æ‰¾åˆ°ä¸¤å¼ å›¾ç‰‡çš„å¯¹åº”ç‚¹

åœ¨è§’ç‚¹çš„å‘¨å›´çš„intensity gradientåœ¨xå’Œyæ–¹å‘å¾ˆé«˜ï¼Œå› ä¸ºå¦‚æœåªæœ‰xæ–¹å‘åˆ™æ²¡æœ‰xæ–¹å‘çš„å˜åŒ–ï¼Œåªæœ‰yæ–¹å‘åŒç†ï¼›è§’ç‚¹æ—¢æœ‰xåˆæœ‰yï¼Œæ‰€ä»¥å˜åŒ–å¾ˆå¤§ï¼Œå› æ­¤intensity gradientå¾ˆé«˜

### 6.2.2 Harris

1. Compute Gaussian derivatives at each pixel, 
2. Compute second moment matrix M in a Gaussian window around each pixel, 
3. Compute corner response function R, 
4. Threshold R,
5. Find local maxima of response function ï¼ˆnonmaximum suppressionï¼‰

**Harris Cornerå¯¹å°ºåº¦å˜æ¢ä¸æ˜¯Invarianceçš„ï¼ï¼**

Harris invariant to brightness changing(intensity shift) and covariant to translation and rotation. In the cases image brightness changing(intensity shift), translation and rotation, Harris corners still can be detected by Harris detector.

### 6.2.3 SIFT

é’ˆå¯¹HArrisè§’ç‚¹æ²¡æœ‰å°ºåº¦ä¸å˜æ€§æå‡ºçš„ï¼Œç›®æ ‡ï¼šå¯ä»¥æ£€æµ‹å‡ºåŒä¸€å›¾ç‰‡æŒ‰ç…§ä¸åŒå°ºåº¦ç¼©æ”¾çš„å¯¹åº”åŒºåŸŸ

Laplacianç®—å­å…·æœ‰å°ºåº¦é€‰æ‹©æ€§ï¼Œå½“laplacianä¸blobå°ºåº¦åŒ¹é…æ—¶ï¼Œåœ¨blobä¸­å¿ƒlaplacianæœ‰æœ€å€¼ï¼Œå°±æ˜¯å°ºåº¦å˜çš„åŒºåŸŸ

SIFTæµç¨‹

<img src="/Users/kevin/Library/Application Support/typora-user-images/image-20220103160311024.png" alt="image-20220103160311024" style="zoom:30%;" />

1. Construct Scale Space(ç”¨ä¸åŒå°ºåº¦çš„é«˜æ–¯æ ¸å·ç§¯å›¾ç‰‡æ¥è·å–ä¸åŒå°ºåº¦ä¸‹çš„å›¾ç‰‡ï¼Œæ¥æ¨¡æ‹ŸçœŸå®ä¸–ç•Œä¸­ç”±äºè¿œè¿‘è·ç¦»é€ æˆçš„å°ºåº¦å’Œæ¨¡ç³Šç¨‹åº¦)
2. Compute Difference of Gaussianï¼Œæ¥è¿‘ä¼¼LoG
3. Find local maxima in scale (Scan each DoG images, look at all neighboring 26 points) <- åŒæ—¶å¯å®ç°éæœ€å¤§å€¼æŠ‘åˆ¶
4. Sub Pixel Locate Potential feature points
5. Assign keypoint orientation

6. Build keypoint descriptors

- å¦‚ä½• Build SIFT Feature descriptorï¼Ÿ

1. Determine the affine region
2. Normalize region
3. Remove the rotational ambiguity
4. Form a descriptor from normalized region

### 6.2.4 Match

å¦‚ä½•åœ¨ä¸¤å¼ å›¾ç‰‡ä¹‹é—´æ‰¾åˆ°true correspondenceï¼Ÿï¼Ÿ

RANSACæµç¨‹

åˆ©å¼Š

# Week7 Mid-Level Stero & Depth

## 7.1 Stereo Camera

Depth information can be recovered using 2 images

### 7.1.1 Coplanar Camera(Simple case)

åœ¨ç›¸æœºå…±é¢çš„æƒ…å†µä¸‹ï¼Œdisparityç­‰äºæŸåƒç´ åœ¨å·¦å³ä¸¤ä¸ªç›¸æœºä¹‹å·® $d = x_L - x_R$

$depth = f\frac{baseline}{disparity}$

é€šè¿‡å…¬å¼å¯ä»¥çœ‹å‡ºï¼Œdisparityä¸depthæˆåæ¯”ï¼Œå³è·ç¦»åƒé¢è¶Šè¿‘çš„ç‚¹ï¼Œåœ¨å·¦å³ç›¸æœºä¸­çš„è§†å·®è¶Šå¤§ï¼Œåä¹‹äº¦ç„¶ã€‚æˆ‘ä»¬æ ¹æ®ä¸¤å¼ å›¾ç‰‡çš„disparityå°±å¯ä»¥è®¡ç®—å‡ºdepth mapã€‚ä½†æ˜¯å¦‚ä½•å¾—åˆ°disparityå‘¢ï¼Ÿé€šè¿‡è®¡ç®—ä¸¤å¼ å›¾ä¸­çš„correspondenceä½ç½®ï¼Œæ¥è·å–disparityã€‚æ‰€ä»¥how to solve stereo correspondence problemæˆäº†å…³é”®é—®é¢˜ã€‚

é€šè¿‡æå¹³é¢æ¥æ‰¾correspondenceã€‚é€šè¿‡å‡ ä½•çº¦æŸå°†æœç´¢èŒƒå›´ç¼©å°åˆ°å¯¹åº”çš„æçº¿ä¸Šã€‚

Stereo Constraints on Correspondenceï¼š

- Epipolar constraintsï¼šé€šè¿‡å‡ ä½•çº¦æŸå°†æœç´¢èŒƒå›´ç¼©å°åˆ°å¯¹åº”çš„æçº¿ä¸Š
- Maximum disparityï¼šå› ä¸ºç‰©ä½“è·ç¦»ç›¸æœºçš„è·ç¦»è¦è¿œè¿œå¤§äºbaselineçš„é•¿åº¦ï¼Œå¦‚æœç›¸æœºè·ç¦»ç‰©ä½“å¤ªè¿‘ï¼Œå°±æ²¡æ³•æ‹åˆ°æœ‰å…±åŒ éƒ¨åˆ†çš„ç…§ç‰‡ï¼Œä¹Ÿå°±æ‰¾ä¸åˆ°corresponding pointsï¼šfails for points closer to cameras than Zmin.
- Continuity
- Uniqueness
- Ordering

åœ¨ç›¸æœºå…±é¢çš„æƒ…å†µä¸‹ï¼Œcorresponding pointsä½äºä¸¤å¼ å›¾ç‰‡çš„æçº¿ä¸Šï¼ˆæçº¿å…±é¢ï¼›ï¼‰

### 7.1.2 Non-Coplanar Camera(Complex case)

åœ¨ç›¸æœºä¸å…±é¢çš„æƒ…å†µä¸‹ï¼Œdisparityç­‰äºæŸåƒç´ åœ¨å·¦å³ä¸¤ä¸ªç›¸æœºè§’åº¦ä¹‹å·® $d = \alpha_L -\alpha_R$

å¦‚æœdå¤§äº0ï¼Œåˆ™è¡¨ç¤ºoutside of the horopter(è½åœ¨horopterä¸Šçš„ç‚¹è§†å·®éƒ½ä¸º0)ï¼›åä¹‹äº¦ç„¶

<img src="/Users/kevin/Library/Application Support/typora-user-images/image-20220103184141305.png" alt="image-20220103184141305" style="zoom:30%;" />

**The steps of Stereo Reconstruction or how to find depth?**

1. Calibration(intrinsic extrinsic parameters)

2. Rectification(use Epipole constraints to find correspondence points in

   1D space)

3. Calculate the disparity(to find Disparity map use similar triangles in

   $$ğ‘=ğ‘“ \frac{T}{ğ‘¥_ğ‘Ÿ âˆ’ ğ‘¥_ğ‘™}$$

4. triangulation(to find Depth map)

## 7.2 Cues to Depth

- Oculomotorï¼ˆçœ¼çƒè¿åŠ¨ï¼‰
  - **Accommodation**: The shape of the lens in the eye, or the depth of the image plane in a camera, is related to the depth of objects that will be in focus. Hence, knowledge of these values provides information about the depth of the object being observed.
  - **Convergence**: The rotation of eyes/cameras in a stereo vision system can vary to fixate objects at different depths. Hence, the angle of convergence provides information about the depth of the object being fixated.
- Monocular (å•ç›®è§†è§‰)
  - **Interposition**: Nearer objects may occlude more distant objects. Hence occlusion (or interposition) provides information about relative depth. 
  - **Size familiarity**: Objects of known size provide depth information, since the smaller the image of the object the greater its depth. 
  - **Texture gradients**: For uniformly textured surfaces, the texture elements get smaller and more closely spaced with increasing depth. 
  - **Linear perspective**: lines that are parallel in the scene converge towards a vanishing point in the image. As the distance between the lines in the image decreases, so depth increases. 
  - **Aerial perspective**: Due to the scattering of light by particles in the atmosphere, distant objects look fuzzier and have lower luminance contrast and colour saturation. 
  - **Shading**: The distribution of light and shadow on objects provides a cue for depth.
- Motion
  - **Motion parallax**: As the camera move sideways, objects closer than the fixation point appear to move in a direction opposite to the camera, while objects further away appear to move in the same direction. The speed of movement increases with distance from the fixation point. 
  - **Optic Flow**: As a camera moves forward or backward, objects closer to the camera move more quickly across the image plane. 
  - **Accretion and deletion**: As a camera moves parts of an object can appear or disappear; these changes in occlusion provides information about relative depth. 
  - **Structure from motion (kinetic depth)** : Movement of an object or of the camera can generate different views of an object that can be combined to recover 3D structure.

# Week8 Video and Motion

## 8.1 Optic flow & Motion flow

Optic flowæ˜¯åˆ©ç”¨å›¾åƒåºåˆ—ä¸­çš„åƒç´ åœ¨æ—¶é—´åŸŸä¸Šçš„å˜åŒ–ã€ç›¸é‚»å¸§ä¹‹é—´çš„ç›¸å…³æ€§æ¥æ‰¾åˆ°çš„ä¸Šä¸€å¸§è·Ÿå½“å‰å¸§é—´å­˜åœ¨çš„å¯¹åº”å…³ç³»ï¼Œè®¡ç®—å‡ºç›¸é‚»å¸§ä¹‹é—´ç‰©ä½“çš„è¿åŠ¨ä¿¡æ¯çš„ä¸€ç§æ–¹æ³•

Motion flowåˆ™æ˜¯çœŸå®ä¸–ç•Œä¸­ï¼Œç‰©ä½“åœ¨æ—¶é—´åŸŸä¸Šçš„å˜åŒ–ã€ç›¸é‚»å¸§ä¹‹é—´çš„ç›¸å…³æ€§

ä¸ºäº†æ‰¾åˆ°Optic flowå°±å¿…é¡»æ‰¾åˆ°ä¸¤frameä¹‹é—´çš„å¯¹åº”ç‚¹

- Feature-based methods
- Direct methods

Constraintsï¼š

- Small motionï¼š (assume optical flow vectors have small magnitude). Fails if relative motion is fast or frame rate is slow
- Spatial coherenceï¼š(assume neighbouring points have similar optical flow). Fails at discontinuities between surfaces at different depths, or surfaces with different motion

æ‰¾åˆ°äº†å¯¹åº”ç‚¹å°±å¯ä»¥è®¡ç®—3dç»“æ„ä¸æ¢å¤motion:

- with knowledge of ego-motion: calculate absolute depth
- Without knowledge of ego-motion:
  - calculate relative depths
  - Time-to-collisionï¼šhow long the camera will collapse with object
  - direction of ego-motion
  - heading of ego-motion

## 8.2 Aperture problem

å­”å¾„é—®é¢˜æŒ‡æ— æ³•é€šè¿‡å•ä¸ªç®—å­ã€è®¡ç®—æŸä¸ªåƒç´ å€¼å˜åŒ–çš„æ“ä½œï¼Œä¾‹å¦‚ï¼šæ¢¯åº¦ã€‘å‡†ç¡®æ— è¯¯åœ°è¯„ä¼°ç‰©ä½“çš„è¿è¡Œè½¨è¿¹ã€‚åŸå› æ˜¯æ¯ä¸€ä¸ªç®—å­åªèƒ½å¤„ç†å®ƒæ‰€è´Ÿè´£å±€éƒ¨åŒºåŸŸçš„åƒç´ å€¼å˜åŒ–ï¼Œç„¶è€ŒåŒä¸€ç§åƒç´ å€¼å˜åŒ–å¯èƒ½æ˜¯ç”±ç‰©ä½“çš„å¤šç§è¿è¡Œè½¨è¿¹å¯¼è‡´ã€‚

<img src="/Users/kevin/Library/Application Support/typora-user-images/image-20220104041958551.png" alt="image-20220104041958551" style="zoom:40%;" />

è§£å†³æ–¹æ¡ˆï¼š

- integrating information from many local motion detectors / image patches, or 
-  by giving preference to image locations where image structure provides unambiguous information about optic flow (e.g. corners).

# Week9 High-Level Vision (Artificial)

## 9.1 Category hierarchy

ä¸Šå±‚æ›´æŠ½è±¡ï¼Œä¸‹å±‚æ›´å…·ä½“

## 9.2 Template Matching

Templateï¼šè¦è¢«recognizedçš„ç‰©ä½“

- æœç´¢æ¯ä¸€å—åŒºåŸŸ
- è®¡ç®—templateä¸image regionçš„ç›¸ä¼¼åº¦
- é€‰å–è¶…è¿‡é˜ˆå€¼çš„æœ€ä½³åŒºåŸŸ

Templates éœ€è¦ä¸ç›®æ ‡ç‰©ä½“éå¸¸ç›¸ä¼¼æ‰èƒ½æ£€æµ‹å‡ºæ¥ï¼Œå¦‚æœç‰©ä½“å‘ç”Ÿäº†å½¢å˜ï¼Œæ—‹è½¬ï¼Œå°±æ— æ³•æ£€æµ‹

è§£å†³æ–¹æ¡ˆï¼šmulti templates for each object

é—®é¢˜ï¼šé®æŒ¡æ— æ³•æ£€æµ‹ï¼Œnot robust to changes in appearance

## 9.3 Similarity Measures

We can **maximise** the following measures

- Cross-correlation
- Normalised cross-correlation ï¼ˆcosine of the angle between i and jï¼‰
- Correlation coefficient

We can **minimise** the following measures

- Sum of Squared Differences:
- Eculidean distance:
- Sum of Absolute Differences: 

## 9.4 Sliding Window

å¯¹äºæ¯ä¸€å—image patchç”¨åˆ†ç±»å™¨æ£€æµ‹æ˜¯å¦åŒ…å«ç‰©ä½“ï¼ˆå°±ä¸ç”¨æ¯”è¾ƒintensity valuesï¼‰

å…ˆç”¨image segmentationå¤„ç†åï¼Œä¼šæé«˜é€Ÿåº¦

## 9.5 Edge Matching

åƒtemplate matchingä¸€æ ·ï¼Œåªä¸è¿‡å…ˆæå–è¾¹ç¼˜

## 9.6 Model-based object recognition

å…ˆå‡è®¾å‡ºç‰©ä½“çš„å½¢çŠ¶ä¸å§¿æ€ï¼Œç„¶ååœ¨å›¾åƒä¸­æç»˜å‡ºç‰©ä½“ï¼Œå†æ¯”è¾ƒ

## 9.7 Intensity histograms

compare histograms to find closes match

Insensitive to small viewpoint changes and spatial configuration

## 9.8 Implicit Shape Model (ISM)

<img src="/Users/kevin/Library/Application Support/typora-user-images/image-20220104000215498.png" alt="image-20220104000215498" style="zoom:30%;" />

## 9.9 Feature-based object recognition

å…ˆæå–SIFTç‰¹å¾

## 9.10 Bag-of-words

<img src="/Users/kevin/Library/Application Support/typora-user-images/image-20220104000621660.png" alt="image-20220104000621660" style="zoom:30%;" />

## 9.11 Geometry Invariants

# Week10 High-Level Vision (Biological)

## 10.1 Theories of Object Recognition

### 10.1.1 Object basedï¼šRecognition by Components

ä¸»è¦æ€è·¯ï¼šæ¯ä¸ªobjectéƒ½ç”¨ä¸€ä¸ª3Dæ¨¡å‹è¡¨ç¤ºï¼Œå°çš„geometric componentsç»„æˆäº†å¤§çš„æ•´ä½“

structural descriptionsï¼šç”¨æ¥è¡¨ç¤ºä¸€ä¸ªç‰©ä½“çš„ç»„æˆéƒ¨åˆ†ä¸å†…éƒ¨å…³ç³»ï¼Œæ¯”å¦‚the cube above cylinder

geometrical icons / geonsï¼š3Dç‰©ä½“ï¼Œæ¯”å¦‚cubeï¼Œsphereï¼Œcylinderï¼Œwedgesï¼Œä¸åŒçš„geonsç»„åˆå¯ä»¥ä»£è¡¨ä¸åŒçš„obj

ä½¿ç”¨geonså¯ä»¥è¾¾æˆviewpoint invarianceçš„ç›®çš„ï¼Œå› ä¸ºdifferent views of the same obj are represented by the same set of goons, in the same arrangement.

Problems:

- å¾ˆéš¾å°†ä¸€å¹…å›¾ç‰‡decomposeæˆå¾ˆå¤šçš„components
- æœ‰å¾ˆå¤šè‡ªç„¶ç‰©ä½“å¾ˆéš¾ç”¨geonsè¡¨ç¤ºå‡ºæ¥ï¼Œæ¯”å¦‚æ ‘
- æ— æ³•è¡¨ç¤ºç»†èŠ‚ç‰¹å¾ï¼Œæˆ–è€…æ— æ³•åŒºåˆ†å¾®å°çš„ç‰©ä½“

### 10.1.2 Image based

3D obj represented by multiple 2D views of the obj

Local(Featural) VS Global(Configural)

Rules VS Prototypes VS Exemplars

- Rules: æ‰€æœ‰æ»¡è¶³æŠ½è±¡çš„è§„åˆ™çš„äº‹ç‰©å±äºä¸€ç±»ã€‚æ¯”å¦‚å››æ¡è…¿ä¼šå«çš„ç”Ÿç‰©ï¼šç‹—ï¼›æœ‰ä¸‰æ¡è¾¹ï¼šä¸‰è§’å½¢ï¼›
- Prototypesï¼šè®¡ç®—æ‰€æœ‰ç±»åˆ«çš„ä¸­ä¸ªä½“çš„å¹³å‡å€¼ï¼Œæ–°ç‰©ä½“ä¸æ¯ä¸ªç±»åˆ«å¹³å‡å€¼æ¯”è¾ƒï¼Œçœ‹å±äºå“ªä¸ªæœ€è¿‘çš„ç±»åˆ«
- Exemplarsï¼šæ¯ä¸ªç±»åˆ«ä¸ªä½“ç”¨å‘é‡è¡¨ç¤ºåä¿å­˜ä¸‹æ¥ï¼Œæ–°ç‰©ä½“ä¸æ¯ä¸ªç±»åˆ«çš„ä¸ªä½“æ¯”è¾ƒï¼Œçœ‹å±äºå“ªä¸ªæœ€è¿‘çš„ç±»åˆ«

Nearest Mean Classifierï¼ˆPrototypesï¼‰

Nearest/K-Nearest Neighbors Classifierï¼ˆExemplarsï¼‰->æ— æ³•å¤„ç†outliersï¼ˆnoiseï¼‰

## 10.2 The Cortical Visual System

### 10.2.1 Pathways

"What" and "Where" pathways: æ²¿ç€pathwaysèµ°ï¼Œneurons preferred stimuli gets more **complex**, receptive fields become **larger**, and there is greater **invariance** to location, sensitivity to stimulus location **decreased**.

### 10.2.2 HMAX

Hierarchical Maxpooling Model:

- S-cells(Simple)ï¼šsumï¼ˆandï¼‰
- C-cells(Complex)ï¼šmaxï¼ˆorï¼‰

åœ¨CNNä¸­å·ç§¯å±‚ç›¸å½“äºHMAXä¸­çš„S-cellsï¼›æ± åŒ–å±‚ç›¸å½“äºHMAXä¸­çš„C-cells

- **Simple cell**: input is from a number of centre-surround cells which have RFs on a common line. These centre-surround neurons are activated by a bar/edge at the correct orientation, resulting in the simple cell responding to a oriented bar/edge at a specific orientation. 
- **Complex cell**: input is from a number of simple cells with the same orientation preference within a small spatial region. A bar/edge at the correct orientation and location to activate one of these simple cells will result in the complex cell responding, and hence, the complex cell responds to to oriented edges with some tolerance to exact location.

## 10.3 Bayesian Inference

<img src="/Users/kevin/Library/Application Support/typora-user-images/image-20220103230840505.png" alt="image-20220103230840505" style="zoom:50%;" />